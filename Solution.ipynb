{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step: 1 -> Install The Dependencies from the requirements.txt or Run the Below Cell to install all the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers git+https://github.com/openai/whisper.git langdetect moviepy rouge-score pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step: 2 ->  Run the Below Cell\n",
    "\n",
    "It take Take any language as Input and Give Transcript and translate the Transcript to English and Generate Summary of the Audio/Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T19:21:18.987475Z",
     "iopub.status.busy": "2024-05-30T19:21:18.987078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter YouTube link or local file path:  /kaggle/input/french-audio/french.wav\n",
      "Speech Recognition Time: 1.94 seconds\n",
      "\n",
      "Transcribed Text:  Parcourant des routes de campagne bueuse et s'adressant jour après jour à des auditoires humides dans des salles de classe pleine de courant d'air pendant 15 jours, il devra se présenter dans un lieu de culte le dimanche matin et pourra venir chez nous immédiatement après.\n",
      "\n",
      "Detected Language: fr\n",
      "\n",
      "Summarization Time: 1.31 seconds\n",
      "\n",
      "Summarization Evaluation:\n",
      "\n",
      "rouge1: 0.81\n",
      "\n",
      "rouge2: 0.80\n",
      "\n",
      "rougeL: 0.81\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Results:\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Translation: Located on a blustery field and scurrying day after day to humid auditoriums in class rooms full of air for 15 days, he must be present in a place. de culte le dimanche matin et peut venir chez nous immédiatement après.\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Summary: Located on a blustery field and scurrying day after day to humid auditoriums in class rooms full of air for 15 days, he must be present in a place.\n",
      "Process another file? (y/n):  y\n",
      "\n",
      "Enter YouTube link or local file path:  /kaggle/input/german-audio/german.wav\n",
      "Speech Recognition Time: 1.11 seconds\n",
      "\n",
      "Transcribed Text:  Ich liebe es, Kaffee zu trinken, und der beste Kaffee, den ich bekommen kann, ist von Roast24 in Hyderabad, Indien.\n",
      "\n",
      "Detected Language: de\n",
      "\n",
      "Summarization Time: 0.45 seconds\n",
      "\n",
      "Summarization Evaluation:\n",
      "\n",
      "rouge1: 1.00\n",
      "\n",
      "rouge2: 1.00\n",
      "\n",
      "rougeL: 1.00\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Results:\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Translation: I love drinking coffee, and the best coffee I can get is from Roast24 in Hyderabad, India.\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Summary: I love drinking coffee, and the best coffee I can get is from Roast24 in Hyderabad, India.\n",
      "Process another file? (y/n):  y\n",
      "\n",
      "Enter YouTube link or local file path:  https://www.youtube.com/watch?v=MNHuttMfnwM\n",
      "MoviePy - Writing audio in extracted_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "\n",
      "Speech Recognition Time: 5.21 seconds\n",
      "\n",
      "Transcribed Text:  El pájaro y la ballena Una historia original de TheFableCottage.com Una vez, hubo un pájaro que amaba a una ballena y una ballena que amaba a un pájaro. Al pájaro le encantaba la hermosa sonrisa de la ballena. Le encantaba cómo nadaba elegantemente por el agua. El pájaro y la ballena se encontraron en la bahía. Hablaron y hablaron. Hablaron de la luna, de las olas y de los barcos en el océano. El pájaro contó chistes que hicieron reír a la ballena. La ballena cantó hermosas canciones que hicieron solo porque un pájaro y una ballena se enamoran. El verano se transformó en otoño y el otoño se transformó en invierno. El océano se volvió frío y todas las ballenas partieron hacia aguas más cálidas. Ven conmigo donde hay aguas cálidas, dijo la ballena. pero primero enséñame a ser una ballena. Así dijo la ballena. Sígueme. Y se sumergió en el agua. De acuerdo dijo el pájaro. Mejor ven conmigo, vivo arriba en los encantilados. Es un lugar maravilloso, es cálido y acogedor, y cada mañana puedes ver el amanecer. Me encanta ver el amanecer, dijo la ballena. Y me encanta estar contigo. Te seguiré a cualquier lugar. la ballena. Cerró los ojos con fuerza y batió sus aletas como el pájaro. Aletió y aletió, arriba y abajo. El agua salpicó en todos lados. ¡Estoy volando! rió. ¡Soy un pájaro! Pero cuando la ballena abrió los ojos, no estaba elevándose en el cielo, todavía estaba en el agua. puedes volar y yo no puedo nadar, ¿dónde podremos vivir juntos? dijo el pájaro. Nos quedaremos aquí, en las olas, dijo la ballena. Pero el pájaro sacudió la cabeza tristemente. ¿A ti te encanta nadar profundo en el océano? dijo. Eso es lo que más te gusta hacer. Nunca serás feliz aquí. Cuando el pájaro y la ballena se querían tanto, se dijeron adiós. Pero nunca se olvidaron el uno del otro. Cada vez que la ballena miraba un pájaro volando alto en el cielo, pensaba en su pájaro. Ella esperaba que él estuviera disfrutando de los cielos de esa manera.\n",
      "\n",
      "Detected Language: es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization Time: 6.41 seconds\n",
      "\n",
      "Summarization Evaluation:\n",
      "\n",
      "rouge1: 0.66\n",
      "\n",
      "rouge2: 0.66\n",
      "\n",
      "rougeL: 0.66\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Results:\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Translation: El pájaro y la ballena An original story from TheFableCottage.com Once, there was a pájaro that amaba to a ballena and a ballena that amaba to a pájaro. Al pájaro le encantaba la hermosa sonrisa de la ballena. pájaro y la ballena encontraron en la baa. Hablaron y hablaron. Hablaron de la luna, de las olas y de los barcos en el océano. pájaro contó chistes que hicieron rer a la ballena. La ballena cantó her beautiful canciones que hicieron solo porque un pájaro y una ballena se enamoran. El verano se transformó en otoo y el otoo se transformó. transformed into winter. The ocean turned cold and all the birds partied towards the most cálid waters. See me where there are cálid waters, said the bird. but first I would like to be a bird. So said the ballerina. Sing me. And he poured in the water. Of course said the pitcher. Better see me, live up in the enchanted. It's a wonderful place, it's beautiful and welcoming, and every morning it's a wonderful place. You can see the amanecer. I love seeing the amanecer, said the ballerina. And I love being counted. I'll go anywhere. Aletió and aletió, up and down. The water dripped in all directions. \"I'm going!\" he said. \"I'm a pájaro!\" But when the ballad opened the eyes, he was not elevating in the heaven, he was still in the earth. water. Can you go and I can't go, where can we live together? said the pharaoh. We will stay here, in the oaths, said the ballerina. But the pharaoh sank his head tragically.                                                                                                                                                       Every time the ballerina looked at a pillar flying high in the heavens, she thought in her pillar. She hoped that he would be enjoying the heavens in that way.\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Summary: Once, there was a pájaro that amaba to a ballena and a ballena that amaba to a pájaro. Al pájaro le encantaba la hermosa sonrisa de la ballena. pájaro y la ballena encontraron en la baa. Hablaron y hablaron. Hablaron de la luna, las olas y de los barcos en el océano. pájaro contó chistes que hicieron rer a la ballena. La ballena cantó her beautiful canciones que hicieron solo porque un pájaro y una ballena se enamoran. El verano se transformed en otoo y el otoo se transformed into winter. The ocean turned cold and all the birds partied towards the most cálid waters. See me where there are cálid waters, said the bird. But first I would like to be a bird. So said the ballerina. Sing me. And he poured in the water. Of course said the pitcher. Better see me, live up in the enchanted\n",
      "Process another file? (y/n):  y\n",
      "\n",
      "Enter YouTube link or local file path:  https://www.youtube.com/watch?v=JhU0yO43b6o\n",
      "MoviePy - Writing audio in extracted_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "\n",
      "Speech Recognition Time: 2.47 seconds\n",
      "\n",
      "Transcribed Text:  Hey there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. All I'm looking for you to do here is to use the YouTube tool to transcribe this message and then click Sync and set the timing so you can get a quick idea about how the whole process works. Well, this wraps up the video. Good luck and I will talk to you about it soon.\n",
      "\n",
      "Detected Language: en\n",
      "\n",
      "Summarization Time: 1.87 seconds\n",
      "\n",
      "Summarization Evaluation:\n",
      "\n",
      "rouge1: 0.89\n",
      "\n",
      "rouge2: 0.89\n",
      "\n",
      "rougeL: 0.89\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Results:\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Translation: Hi there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. All I'm looking for you to do here is to use the YouTube tool to transcribe this message and then click Sync and set the timing so you can get a quick idea about how the whole process works. Well, this wraps up the video. Good luck and I will talk to you about it.\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Summary: Hi there, this is a quick and silly video to allow you to experiment a little bit with the process of transcription on YouTube. All I'm looking for you to do here is to use the YouTube tool to transcribe this message and then click Sync and set the timing so you can get a quick idea about how the whole process works.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langdetect import detect, LangDetectException\n",
    "from moviepy.editor import VideoFileClip\n",
    "from rouge_score import rouge_scorer\n",
    "import time\n",
    "from pytube import YouTube\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Loading Models\n",
    "whisper_model_id = \"openai/whisper-medium\"  # Whisper model\n",
    "rag_model_name = \"google/flan-t5-base\"\n",
    "\n",
    "whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    whisper_model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ").to(device)\n",
    "whisper_processor = AutoProcessor.from_pretrained(whisper_model_id)\n",
    "\n",
    "rag_model = AutoModelForSeq2SeqLM.from_pretrained(rag_model_name).to(device)\n",
    "rag_tokenizer = AutoTokenizer.from_pretrained(rag_model_name, add_special_tokens=True)\n",
    "\n",
    "# Pipelines\n",
    "whisper_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_model,\n",
    "    tokenizer=whisper_processor.tokenizer,\n",
    "    feature_extractor=whisper_processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=60, \n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "rag_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=rag_model,\n",
    "    tokenizer=rag_tokenizer,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Rouge for Summarization Evaluation\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def chunk_text(text, max_length=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        if len(\" \".join(current_chunk + [word])) <= max_length:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def translate_chunks(chunks):\n",
    "    translated_text = \"\"\n",
    "    for chunk in chunks:\n",
    "        translation = rag_pipeline(f\"Translate the following text to English: {chunk}\", max_length=300, num_beams=5)  \n",
    "        translated_chunk = translation[0]['generated_text']\n",
    "        translated_text += \" \" + translated_chunk\n",
    "    return translated_text.strip()\n",
    "\n",
    "def process_media_file(media_file):\n",
    "    try:\n",
    "        # Extract audio from video if needed\n",
    "        if media_file.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_clip = VideoFileClip(media_file)\n",
    "            audio_file = \"extracted_audio.wav\"\n",
    "            video_clip.audio.write_audiofile(audio_file)\n",
    "        else:\n",
    "            audio_file = media_file\n",
    "\n",
    "        # Speech Recognition \n",
    "        start_time = time.time() \n",
    "        result = whisper_pipe(audio_file)  \n",
    "        end_time = time.time()\n",
    "        print(f\"Speech Recognition Time: {end_time - start_time:.2f} seconds\")\n",
    "        text = result[\"text\"]\n",
    "        print(f\"Transcribed Text: {text}\")\n",
    "\n",
    "        # Language Detection with Error Handling\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            print(f\"Detected Language: {lang}\")\n",
    "        except LangDetectException:\n",
    "            lang = \"unknown\"\n",
    "            print(f\"Language could not be detected.\")\n",
    "\n",
    "        # Translation using RAG with chunking\n",
    "        chunks = chunk_text(text, max_length=200)\n",
    "        translation_text = translate_chunks(chunks)\n",
    "\n",
    "        # Summarization using RAG \n",
    "        start_time = time.time()\n",
    "        summary = rag_pipeline(f\"Give the precise Summary of: {translation_text}\", max_length=300, num_beams=5)    \n",
    "        end_time = time.time()\n",
    "        print(f\"Summarization Time: {end_time - start_time:.2f} seconds\")\n",
    "        summary_text = summary[0]['generated_text']\n",
    "\n",
    "        # Evaluating Summarization \n",
    "        scores = rouge.score(summary_text, translation_text)  # Evaluate against translated text\n",
    "        print(\"Summarization Evaluation:\")\n",
    "        for key, value in scores.items():\n",
    "            print(f\"{key}: {value.fmeasure:.2f}\")\n",
    "\n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"translation\": translation_text,  \n",
    "            \"summary\": summary_text,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return None  \n",
    "\n",
    "def process_youtube_link(youtube_link):\n",
    "    try:\n",
    "        # Download the video\n",
    "        yt = YouTube(youtube_link)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "        stream.download(filename='downloaded_video.mp4')\n",
    "\n",
    "        # Extract audio from the downloaded video\n",
    "        video_clip = VideoFileClip('downloaded_video.mp4')\n",
    "        audio_file = \"extracted_audio.wav\"\n",
    "        video_clip.audio.write_audiofile(audio_file)\n",
    "\n",
    "        return process_media_file(audio_file)  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing YouTube link: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        media_input = input(\"Enter YouTube link or local file path: \")\n",
    "        if media_input.startswith('https://www.youtube.com'):\n",
    "            results = process_youtube_link(media_input)\n",
    "        else:\n",
    "            results = process_media_file(media_input)\n",
    "\n",
    "        if results is not None:\n",
    "            print(\"----------------------------------\")\n",
    "            print(\"Results:\")\n",
    "            print(\"----------------------------------\")\n",
    "            print(f\"Translation: {results['translation']}\")  \n",
    "            print(\"----------------------------------\")\n",
    "            print(f\"Summary: {results['summary']}\")\n",
    "        \n",
    "        continue_processing = input(\"Process another file? (y/n): \")\n",
    "        if continue_processing.lower() != 'y':\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Cell Takes any language as Input and Give Transcript and translate the Transcript to French and Generate Summary of the Audio/Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T18:40:42.017143Z",
     "iopub.status.busy": "2024-05-30T18:40:42.016640Z",
     "iopub.status.idle": "2024-05-30T18:41:12.296291Z",
     "shell.execute_reply": "2024-05-30T18:41:12.295322Z",
     "shell.execute_reply.started": "2024-05-30T18:40:42.017114Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter YouTube link or local file path:  /kaggle/input/audio/sample.mp3\n",
      "Speech Recognition Time: 1.91 seconds\n",
      "\n",
      "Transcribed Text:  Going along slushy country roads and speaking to damp audiences in drafty school rooms day after day for a fortnight, he will have to put in an appearance at some place of worship on Sunday morning and he can come to us immediately afterwards.\n",
      "\n",
      "Detected Language: en\n",
      "\n",
      "Translation Time: 3.63 seconds\n",
      "\n",
      "Summarization Time: 3.53 seconds\n",
      "\n",
      "Summarization Evaluation:\n",
      "\n",
      "rouge1: 0.97\n",
      "\n",
      "rouge2: 0.95\n",
      "\n",
      "rougeL: 0.97\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Results:\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Translation: Pour une semaine, il y aura lieu à travers des rues rurales et à parler à des audiences humides dans des salles d'école à l'insuffisance, et il y aura lieu à s'attendre à l'ouverture d'un église et à s'attendre à nous.\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Summary: Pour une semaine, il y aura lieu à travers des rues rurales et à parler à des audiences humides dans des salles d'école à l'insuffisance, et il y aura lieu à s'attendre à l'ouverture d'une église et à s'attendre à nous.\n",
      "Process another file? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langdetect import detect, LangDetectException\n",
    "from moviepy.editor import VideoFileClip\n",
    "from rouge_score import rouge_scorer\n",
    "import time\n",
    "from pytube import YouTube  \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Loading Models\n",
    "whisper_model_id = \"openai/whisper-large-v3\"  # Whisper model\n",
    "rag_model_name = \"google/flan-t5-large\" \n",
    "\n",
    "whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    whisper_model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ").to(device)\n",
    "whisper_processor = AutoProcessor.from_pretrained(whisper_model_id)\n",
    "\n",
    "rag_model = AutoModelForSeq2SeqLM.from_pretrained(rag_model_name).to(device)\n",
    "\n",
    "rag_tokenizer = AutoTokenizer.from_pretrained(rag_model_name, add_special_tokens=True)\n",
    "\n",
    "# Pipelines\n",
    "whisper_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper_model,\n",
    "    tokenizer=whisper_processor.tokenizer,\n",
    "    feature_extractor=whisper_processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=60, \n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "rag_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=rag_model,\n",
    "    tokenizer=rag_tokenizer,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Rouge for Summarization Evaluation\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def process_media_file(media_file):\n",
    "    try:\n",
    "        # Extract audio from video if needed\n",
    "        if media_file.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_clip = VideoFileClip(media_file)\n",
    "            audio_file = \"extracted_audio.wav\"\n",
    "            video_clip.audio.write_audiofile(audio_file)\n",
    "        else:\n",
    "            audio_file = media_file\n",
    "\n",
    "        # Speech Recognition \n",
    "        start_time = time.time() \n",
    "        result = whisper_pipe(audio_file)  \n",
    "        end_time = time.time()\n",
    "        print(f\"Speech Recognition Time: {end_time - start_time:.2f} seconds\")\n",
    "        text = result[\"text\"]\n",
    "        print(f\"Transcribed Text: {text}\")\n",
    "\n",
    "        # Language Detection with Error Handling\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            print(f\"Detected Language: {lang}\")\n",
    "        except LangDetectException:\n",
    "            lang = \"unknown\"\n",
    "            print(f\"Language could not be detected.\")\n",
    "\n",
    "        # Translation using RAG \n",
    "        start_time = time.time()\n",
    "        translation = rag_pipeline(f\"Translate the Following to French: {text}\", max_length=100, num_beams=5)  \n",
    "        end_time = time.time()\n",
    "        print(f\"Translation Time: {end_time - start_time:.2f} seconds\")\n",
    "        translation_text = translation[0]['generated_text']\n",
    "        # Filter special tokens from translation \n",
    "        translation_text = translation_text.replace(\"<extra_id_0>\", \"\").replace(\"<extra_id_1>\", \"\").replace(\"<extra_id_2>\", \"\")  # Add more replacements as needed\n",
    "\n",
    "        # Summarization using RAG \n",
    "        start_time = time.time()\n",
    "        summary = rag_pipeline(f\"Summarize it precisely: {translation_text}\", max_length=100, num_beams=5)    \n",
    "        end_time = time.time()\n",
    "        print(f\"Summarization Time: {end_time - start_time:.2f} seconds\")\n",
    "        summary_text = summary[0]['generated_text']\n",
    "\n",
    "        # Evaluating Summarization \n",
    "        scores = rouge.score(summary_text, translation_text)  # Evaluate against translated text\n",
    "        print(\"Summarization Evaluation:\")\n",
    "        for key, value in scores.items():\n",
    "            print(f\"{key}: {value.fmeasure:.2f}\")\n",
    "\n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"translation\": translation_text,  \n",
    "            \"summary\": summary_text,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return None  \n",
    "\n",
    "def process_youtube_link(youtube_link):\n",
    "    try:\n",
    "        # Download the video\n",
    "        yt = YouTube(youtube_link)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "        stream.download(filename='downloaded_video.mp4')\n",
    "\n",
    "        # Extract audio from the downloaded video\n",
    "        video_clip = VideoFileClip('downloaded_video.mp4')\n",
    "        audio_file = \"extracted_audio.wav\"\n",
    "        video_clip.audio.write_audiofile(audio_file)\n",
    "\n",
    "        return process_media_file(audio_file)  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing YouTube link: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        media_input = input(\"Enter YouTube link or local file path: \")\n",
    "        if media_input.startswith('https://www.youtube.com'):\n",
    "            results = process_youtube_link(media_input)\n",
    "        else:\n",
    "            results = process_media_file(media_input)\n",
    "\n",
    "        if results is not None:\n",
    "            print(\"----------------------------------\")\n",
    "            print(\"Results:\")\n",
    "            print(\"----------------------------------\")\n",
    "            print(f\"Translation: {results['translation']}\")  \n",
    "            print(\"----------------------------------\")\n",
    "            print(f\"Summary: {results['summary']}\")\n",
    "        \n",
    "        continue_processing = input(\"Process another file? (y/n): \")\n",
    "        if continue_processing.lower() != 'y':\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5103454,
     "sourceId": 8542344,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5103490,
     "sourceId": 8542388,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5103610,
     "sourceId": 8542553,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5103993,
     "sourceId": 8543099,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5105671,
     "sourceId": 8545546,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5120095,
     "sourceId": 8564494,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
